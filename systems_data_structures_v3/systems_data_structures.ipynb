{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "monetary-recovery",
   "metadata": {
    "id": "monetary-recovery"
   },
   "source": [
    "# Project 1 - Building the Backend of an AirBnB Website\n",
    "\n",
    "The growth of the homesharing and short-term rental markets has presented opportunities and challenges for communities globally. While for some it encourages tourism and provides additional income streams, for others it exacerbates affordable housing shortages. You decide you can create a website sharing the actual data. In this project you will build the \"backend\" for that website. The following tasks will guide you to experiment with the optimal data structures to store information about listings and their reviews, consider the algorithmic choices you might make to traverse those data structures and even explore the underlying data types you will store the data as. Your goal is to make all of the programs as efficient as possible!\n",
    "\n",
    "In this project, you will be given a handful of functionalities you are expected to implement for the backend of the website. For each functionality you will use, upgrade or build a data structure to store the data you need for that functionality and determine how to traverse that data efficiently to serve information on your website.\n",
    "\n",
    "**General note**: You may notice there are several code cells with the tag `excluded_from_script`. These code cells will not be run by the autograder, and you should make sure to preserve these tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8ea7c-8cde-436b-85e6-91b46e7ba55f",
   "metadata": {
    "id": "2dd8ea7c-8cde-436b-85e6-91b46e7ba55f"
   },
   "source": [
    "We start by implementing relevant packages. Note that you do not need to use any NumPy, Pandas or Sklearn functions in this project; they are only imported to set up the dataset and local test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "second-flower",
   "metadata": {
    "executionInfo": {
     "elapsed": 6252,
     "status": "ok",
     "timestamp": 1738590508453,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "second-flower"
   },
   "outputs": [],
   "source": [
    "import random, string, hashlib, re, collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23236f1b",
   "metadata": {
    "id": "23236f1b"
   },
   "source": [
    "To start, run the following cell to download the data file. Note that this only needs to be run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9317458",
   "metadata": {
    "executionInfo": {
     "elapsed": 22752,
     "status": "ok",
     "timestamp": 1738590739209,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "d9317458",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'http://clouddatascience.blob.core.windows.net/s21-foundation-data-science/systems_data_structures/test_cities.csv'\n",
    "r = requests.get(url)\n",
    "with open('test_cities.csv', 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hindu-coral",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13260,
     "status": "ok",
     "timestamp": 1738590755794,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "hindu-coral",
    "outputId": "107e704b-6145-4193-91f9-1bf7595688cd",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-89107de13a6a>:1: DtypeWarning: Columns (0,1,3,22,28,29,41,45,46,54,61,68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  airbnb_data = pd.read_csv('test_cities.csv')\n"
     ]
    }
   ],
   "source": [
    "airbnb_data = pd.read_csv('test_cities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93c5e11-d233-4e34-a881-679f243e5f4a",
   "metadata": {
    "id": "d93c5e11-d233-4e34-a881-679f243e5f4a"
   },
   "source": [
    "You may see a `DTypeWarning` from the above cell, but you don't need to worry about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-moisture",
   "metadata": {
    "id": "severe-moisture"
   },
   "source": [
    "## Question 1: Analyzing runtime performance and memory requirements of different datatypes (10 points)\n",
    "\n",
    "One functionality that we want is the ability to predict a listing's price based on its features (e.g., locations, amenities). In addition, this feature should be available on the user's phones, which have limited memory and processing capabilities. We have the option to store our data and model in one of three types: 16-bit floating point, 32-bit floating point, or 64-bit floating point. We also have three criteria to evaluate each option:\n",
    "\n",
    "1. How much memory does it take to store the model?\n",
    "1. How long does it take to perform model prediction?\n",
    "1. How good is the model's prediction?\n",
    "\n",
    "To answer these questions, let's try out each of our datatype option on a synthetic dataset. Here we assume that a linear regression model is used to carry out the prediction.\n",
    "\n",
    "Run the code cell below; while you don't need to know the specifics of the NumPy operations that are used, make sure you understand the high-level role of each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5e4794-d72a-4e83-a480-feeeff8492e2",
   "metadata": {
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1738590857588,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "ef5e4794-d72a-4e83-a480-feeeff8492e2"
   },
   "outputs": [],
   "source": [
    "def construct_dataset():\n",
    "    \"\"\"\n",
    "    Generate the input matrix data (X) and output label vector (y) for a regression problem\n",
    "    See https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html for more details\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    data = make_regression(n_samples=10000, random_state=42)\n",
    "    X, y = data[0], data[1]\n",
    "    X = np.concatenate((np.ones((len(X),1)), X), axis=1)\n",
    "    return X, y\n",
    "\n",
    "def train_linear_regression_model(X, y):\n",
    "    \"\"\"\n",
    "    Train a linear regression model to predict the output label vector y based on the input data matrix X\n",
    "    The output is a weight vector w such that Xw is closest to y, in terms of Mean Squared Erroor\n",
    "    \"\"\"\n",
    "    w = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    return w\n",
    "\n",
    "def compute_memory_usage(model):\n",
    "    \"\"\"\n",
    "    Compute the number of bytes needed to store the model vector\n",
    "    \"\"\"\n",
    "    return model.nbytes\n",
    "\n",
    "def compute_prediction_runtime(X, model, N=1000):\n",
    "    \"\"\"\n",
    "    Record the average time taken to perform prediction, sampled from 1000 runs\n",
    "    \"\"\"\n",
    "    total_time = 0\n",
    "    for _ in range(N):\n",
    "        start = datetime.now()\n",
    "        y = X @ model\n",
    "        end = datetime.now()\n",
    "        total_time += (end - start).total_seconds()\n",
    "    return total_time / N\n",
    "\n",
    "def compute_prediction_error(X, model, y_true):\n",
    "    \"\"\"\n",
    "    Compute the Mean Squared Error from the vector of predicted labels and the vector of true labels\n",
    "    \"\"\"\n",
    "    y_predicted = X @ model\n",
    "    return np.mean((y_predicted - y_true)**2)\n",
    "\n",
    "def evaluate_dtype(dtype):\n",
    "    \"\"\"\n",
    "    Return the memory usage, prediction runtime and prediction error when training a linear regression model with the specified data type\n",
    "    \"\"\"\n",
    "    # train the model on 60% of the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(*construct_dataset(), test_size = 0.4)\n",
    "    model = train_linear_regression_model(X_train, y_train)\n",
    "\n",
    "    # convert the test data and trained model vector to the specified dtype\n",
    "    X_test, model = X_test.astype(dtype), model.astype(dtype)\n",
    "\n",
    "    # perform evaluation\n",
    "    memory_usage = compute_memory_usage(model)\n",
    "    prediction_runtime = compute_prediction_runtime(X_test, model)\n",
    "    prediction_error = compute_prediction_error(X_test, model, y_test)\n",
    "    print(f\"A model stored in data type {dtype} consumes {memory_usage} bytes, takes {prediction_runtime} seconds to perform prediction on average, and has a prediction error of {prediction_error}\")\n",
    "    return memory_usage, prediction_runtime, prediction_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff88f67-56cd-4e1f-a530-1b02cf786100",
   "metadata": {
    "id": "7ff88f67-56cd-4e1f-a530-1b02cf786100"
   },
   "source": [
    "Now that the set up has finished, let's begin the evaluation! Run the code cell below, then report your finding in the `evaluate_data_type` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52bb521d-9e1c-44d2-94d0-36be42af9ae4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4907,
     "status": "ok",
     "timestamp": 1738590868263,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "52bb521d-9e1c-44d2-94d0-36be42af9ae4",
    "outputId": "014efd2d-536e-4a93-830e-4d7e1e70984a",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A model stored in data type <class 'numpy.float16'> consumes 202 bytes, takes 0.004188534999999999 seconds to perform prediction on average, and has a prediction error of 0.004513716253473727\n",
      "A model stored in data type <class 'numpy.float32'> consumes 404 bytes, takes 0.00013114199999999984 seconds to perform prediction on average, and has a prediction error of 1.61660029609516e-10\n",
      "A model stored in data type <class 'numpy.float64'> consumes 808 bytes, takes 0.00016148600000000162 seconds to perform prediction on average, and has a prediction error of 3.295476794845363e-27\n"
     ]
    }
   ],
   "source": [
    "evaluate_dtype(np.float16);\n",
    "evaluate_dtype(np.float32);\n",
    "evaluate_dtype(np.float64);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-legend",
   "metadata": {
    "id": "physical-legend"
   },
   "source": [
    "Based on the printouts above, fill in the four variables `fastest`, `slowest`, `least_memory`, `best_test_err` in the `select_data_type` function. In particular,\n",
    "* Each variable should hold one of the three string values: `\"float16\"`, `\"float32\"`, `\"float64\"`.\n",
    "* `fastest` reports the datatype that yields the lowest **prediction** time\n",
    "* `slowest` reports the datatype that yields the highest **prediction** time\n",
    "* `least_memory` reports the datatype that yields the lowest number of bytes\n",
    "* `best_test_err` reports the datatype that has the lowest test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bf72e85",
   "metadata": {
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1738591175271,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "4bf72e85"
   },
   "outputs": [],
   "source": [
    "def evaluate_data_type():\n",
    "    fastest = \"float32\"\n",
    "    slowest = \"float16\"\n",
    "    least_memory = \"float16\"\n",
    "    best_test_err = \"float64\"\n",
    "\n",
    "    return fastest, slowest, least_memory, best_test_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62e52590-914a-4fb1-a6d8-eda092e3795a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 116,
     "status": "ok",
     "timestamp": 1738591176670,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "62e52590-914a-4fb1-a6d8-eda092e3795a",
    "outputId": "b83942da-1e49-4ee3-ca8b-b6b69ed15974",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed! (This does not guarantee your answer is correct, this just indicates that your answer format is correct)\n"
     ]
    }
   ],
   "source": [
    "def test_evaluate_data_type():\n",
    "    assert all(answer in [\"float16\", \"float32\", \"float64\"] for answer in evaluate_data_type())\n",
    "    print(\"All tests passed! (This does not guarantee your answer is correct, this just indicates that your answer format is correct)\")\n",
    "\n",
    "test_evaluate_data_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-idaho",
   "metadata": {
    "id": "considered-idaho"
   },
   "source": [
    "Now you have a good understanding of the trade-offs between different data types. Here are some other points on this topic to think about:\n",
    "* Note that in our implementation of `evaluate_dtype`, the data type conversion only takes place after the linear regression model has been trained. The reason is that model training happens on our side, so we are typically not too concerned about memory or runtime constraints. However, once a model has been trained, it will be deployed to the client side, which could be a mobile phone or a smart watch with very limited resources; in this case, choosing the appropriate data type to store the model becomes more important. This technique is called [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization).\n",
    "* Were you surprised about the data type that led to the slowest inference time? Why may this be the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-bundle",
   "metadata": {
    "id": "mysterious-bundle"
   },
   "source": [
    "## Question 2: Filtering user ids given blacklist and whitelist\n",
    "\n",
    "Some AirBnB users exhibit bad behaviors (e.g., they are rude to their hosts) and are banned from the platform. The IDs of these users are stored in the text file `blacklist.txt`. We also have a file `whitelist.txt`, which stores the ids of users that are not banned. If the same user id appears in both `blacklist.txt` and `whitelist.txt`, the white list will take priority, i.e., that user is **not** banned. If the input user ID isn’t in the blacklist and isn’t in the whitelist, it will be mapped to `False` (that user is not banned).\n",
    "\n",
    "Over the course of the next two tasks, you will build a filter so that, given an input list of user IDs, we map each ID to the boolean `True` if it belongs to a banned user, and `False` otherwise. We will divide this into two separate tasks:\n",
    "\n",
    "1. Selecting appropriate data structures to store the blacklisted and whitelisted user IDs.\n",
    "1. Perform the mapping based on these data structures.\n",
    "\n",
    "We provide the starting code for sub-task 1 in the function `read_blacklist_and_whitelist` below, which saves the ids into two Python lists. As lists have linear search time, they are not optimal for this task. *What data structures are similar to a list?* **You first objective is to modify this code to store the data in a more efficient container, to optimize for sub-task 2**.\n",
    "\n",
    "<span style=\"color:green\">(Hint: Don't overthink it, changing data structures in Python is very straightforward)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07286af4",
   "metadata": {
    "executionInfo": {
     "elapsed": 108,
     "status": "ok",
     "timestamp": 1738591540881,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "07286af4"
   },
   "outputs": [],
   "source": [
    "def read_blacklist_and_whitelist(blacklist_file, whitelist_file):\n",
    "    '''\n",
    "    NOTE: you should change the data structure used for storing the blacklisted and whitelisted IDs\n",
    "\n",
    "    Reads the blacklist and whitelist from input files and store them into appropriate data structures\n",
    "\n",
    "    args:\n",
    "        blacklist_file (str) : file path of blacklist, each line is separate id\n",
    "        whitelist_file (str) : file path of whitelist, each line is separate id\n",
    "\n",
    "    returns: Tuple(blacklist, whitelist)\n",
    "        blacklist (Collection[int]) : a collection of integer ids that belong to the black list\n",
    "        whitelist (Collection[int]) : a collection of integer ids that belong to the white list\n",
    "    '''\n",
    "    with open(blacklist_file) as f:\n",
    "        blacklist = set(int(x.strip()) for x in f.readlines())\n",
    "\n",
    "    with open(whitelist_file) as f:\n",
    "        whitelist = set(int(x.strip()) for x in f.readlines())\n",
    "\n",
    "    return blacklist, whitelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1d628-43de-4f44-b69c-76ae230dfdee",
   "metadata": {
    "id": "50f1d628-43de-4f44-b69c-76ae230dfdee"
   },
   "source": [
    "We now store the returned blacklist and whitelist as global variables, so that they can be accessed in later tasks. If you later change your implementation of `read_blacklist_and_whitelist`, make sure to rerun this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nominated-praise",
   "metadata": {
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1738591542691,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "nominated-praise",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "blacklist, whitelist = read_blacklist_and_whitelist(\"blacklist.txt\", \"whitelist.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-encoding",
   "metadata": {
    "id": "further-encoding"
   },
   "source": [
    "### Question 2.1: Checking if a single user is banned (10 points)\n",
    "Now let's move on to sub-task 2; we will consider a simple case first. Implement the function `check_single_id` that checks for whether a single user ID is banned or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "through-sally",
   "metadata": {
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1738591836332,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "through-sally"
   },
   "outputs": [],
   "source": [
    "def check_single_id(id_to_check, blacklist, whitelist):\n",
    "    '''\n",
    "    Checks whether an input ID is banned, based on the stored blacklist and whitelist.\n",
    "\n",
    "    args:\n",
    "        id_to_check (int) : the user ID that you need to check\n",
    "        blacklist (set[int]) : a set storing all of the blacklisted IDs\n",
    "        whitelist (set[int]) : a set storing all of the whitelisted IDs\n",
    "\n",
    "    returns:\n",
    "        id_state (bool) : True if id_to_check belongs to a banned user, and False otherwise\n",
    "    '''\n",
    "    if id_to_check in whitelist:\n",
    "        return False\n",
    "\n",
    "    if id_to_check in blacklist:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afraid-candy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10166,
     "status": "ok",
     "timestamp": 1738591852653,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "afraid-candy",
    "outputId": "f341ffb4-9687-44a2-c2be-13bca3e6af23",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n",
      "126 ns ± 39.4 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def test_check_single_id():\n",
    "    blacklist, whitelist = read_blacklist_and_whitelist(\"blacklist.txt\", \"whitelist.txt\")\n",
    "    assert check_single_id(59735, blacklist, whitelist) == False, \"Check that you handle cases when id is in both blacklist and whitelist!\"\n",
    "    assert check_single_id(5935, blacklist, whitelist) == True, \"Check that you handle cases when id is in blacklist and not in whitelist!\"\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_check_single_id()\n",
    "\n",
    "# let's also see how long it takes to run this function\n",
    "%timeit check_single_id(59735, blacklist, whitelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-gossip",
   "metadata": {
    "id": "crazy-gossip"
   },
   "source": [
    "### Question 2.2: Filtering list of ids (10 points)\n",
    "Now we move on to the real filtering task. Implement the function `check_list_ids` which, given an input list of IDs, maps each ID to the boolean `True` if it belongs to a banned user, and `False` otherwise. You can either reuse your implementation of `check_single_id`, or implement this task from scratch. Note that the input list of IDs may have very large size, so make sure you do not perform any redundant or repeated operations.\n",
    "\n",
    "**Note:** The tests in this course not only test the accuracy of functions that we ask you to write, but efficiency as well. Check the autograder feedback for more information.\n",
    "          If the autograder feedback and the grades for all tasks become empty, the entire assignment has timed out. You will need to identify the function that is causing the timeout, and optimize it accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdeaec48",
   "metadata": {
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1738593508550,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "cdeaec48"
   },
   "outputs": [],
   "source": [
    "def check_list_ids(ids_list, blacklist, whitelist):\n",
    "    '''\n",
    "    Checks whether each ID in an input list of IDs is banned, based on the stored blacklist and whiteliist\n",
    "\n",
    "    args:\n",
    "        input_ids (List[int]) : the user ID that you need to check\n",
    "        blacklist (collections[int]) : a data structure storing all of the blacklisted IDs\n",
    "        whitelist (collections[int]) : a data structure storing all of the whitelisted IDs\n",
    "\n",
    "    returns:\n",
    "        List[bool] : a list having the same length as input_ids, where the entry at index i\n",
    "            is True if input_ids[i] is banned, and False otherwise\n",
    "    '''\n",
    "    return [check_single_id(id, blacklist, whitelist) for id in ids_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "subtle-happening",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2851,
     "status": "ok",
     "timestamp": 1738593512766,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "subtle-happening",
    "outputId": "81e1e93c-e48e-463a-b8c0-0b6f98e2b6d4",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n",
      "273 ms ± 9.45 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def test_check_list_ids():\n",
    "    test_input_ids = [15795, 860, 76820, 54886, 6265, 82386, 37194, 87498, 44131, 60263]\n",
    "    ref = [False, True, True, False, True, False, False, False, False, False]\n",
    "    assert check_list_ids(test_input_ids, blacklist, whitelist) == ref\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_check_list_ids()\n",
    "\n",
    "# let's also see how long it takes to run this function\n",
    "random.seed(42)\n",
    "test_input_ids = [random.randint(0, 100000) for x in range(1000000)]\n",
    "%timeit check_list_ids(test_input_ids, blacklist, whitelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcb7594-1f28-46aa-9e77-d09bf34b4a46",
   "metadata": {
    "id": "6bcb7594-1f28-46aa-9e77-d09bf34b4a46"
   },
   "source": [
    "The autograder will test your code on an input list of roughly 100000 IDs as well, so make sure everything is optimized!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-eleven",
   "metadata": {
    "id": "aerial-eleven"
   },
   "source": [
    "## Question 3: High performance FIFO storage system (20 points)\n",
    "Next, you want to *dynamically* display the descriptions of AirBnB homes to the user. Imagine that the user enters a search query to AirBnb and gets an initial collection of search results. Then, the user may choose to alter their search query in some ways (for example, changing the start and end date of their stay), causing some new listings to be inserted to the search results, and some old listings to be removed. Your task is to identify a data structure which can efficiently perform these insertion/removal operations. To simplify the context, we will further assume that, when a removal operation takes place, only the oldest element in the collection is removed (oldest in the sense that it was added to the collection before any other element) -- in other words, your collection of search results behaves in a First In First Out (FIFO) manner.\n",
    "\n",
    "In the cell below, we provide a starting implementation of the [generator function](https://wiki.python.org/moin/Generators) `Storage`, which takes as input an initial list of AirBnB homes `initial_data`, as well as a data socket `data_socket`. `data_socket` is a Python generator that iteratively yields the next operation which should be performed on `initial_data`:\n",
    "* If `data_socket` yields the string `\"generate\"`, the oldest element in `initial_data` should be removed and yielded by your function, unless `initial_data` is currently empty. You can assume the elements in `initial_data` are in the same order that you would need to yield them -- the oldest element is at the beginning of the list.\n",
    "* If `data_socket` yields any other string `x`, insert `x` to `initial_data`.\n",
    "\n",
    "The current implementation simply operates directly on the list `initial_data`, which may not be the most efficient approach (recall that removing from the head of a list is costly).\n",
    "\n",
    "**Your task is to move the elements of `initial_data` to a more suitable data structure and reimplement the insertion/removal operations accordingly on this new data structure.**\n",
    "\n",
    "**Example:** let's say `initial_data = [\"10\", \"20\"]` and `data_socket` yields the following strings: `\"30\", \"generate\", \"generate\", \"generate\", \"generate\", \"40\", \"generate\", \"50\"`. Then you should:\n",
    "1. Add `\"30\"` to `initial_data`\n",
    "1. Remove and yield the four oldest elements in `initial_data`, if they exist.\n",
    "1. Add `\"40\"` and `\"50\"` to `initial_data`.\n",
    "1. Finally, `Storage(initial_data, data_socket)` becomes a generator that yields `\"10\", \"20\", \"30\", \"40\"` (because `\"10\"` was removed from `initial_data` first, followed by `\"20\", \"30\", \"40\"`).\n",
    "\n",
    "<span style=\"color:green\">(Hint: Python's standard library offers a variety of data structures. Refer back to the Python Data Structures primer to identify which library contains the appropriate data structure for this task.)</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80a8f2d1",
   "metadata": {
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1738593945277,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "80a8f2d1"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def Storage(initial_data, data_socket):\n",
    "    '''\n",
    "    NOTE: You should modify this function to be more efficient. Feel free to change ANY PART OF THE CODE TO MAKE IT FASTER.\n",
    "\n",
    "    Dynamically update the collection of search results based on the generator data_socket and the initial result collection initial_data\n",
    "\n",
    "    args:\n",
    "        initial_data (List[Object]) - the initial collection of search results\n",
    "        data_socket (generator [Object|String]) - a generator that yields either some object or the string \"generate\"\n",
    "\n",
    "    yields:\n",
    "        Object from initial_data or data_socket\n",
    "    '''\n",
    "    data_queue = deque(initial_data)\n",
    "    for item in data_socket():\n",
    "        if item == \"generate\":\n",
    "            if len(data_queue) > 0:\n",
    "                yield data_queue.popleft()\n",
    "        else:\n",
    "            data_queue.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "durable-craft",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1738593948319,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "durable-craft",
    "outputId": "9106a20e-e828-46c6-b21b-d0e2ac0b7e5c",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n",
      "111 ms ± 9.86 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def test_storage():\n",
    "    def test_socket():\n",
    "        for x in [3,\"generate\",\"generate\",\"generate\",\"generate\",4,\"generate\",5]:\n",
    "            yield x\n",
    "\n",
    "    assert list(Storage([1,2], test_socket)) == [1, 2, 3, 4]\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_storage()\n",
    "\n",
    "# let's also see how long it takes to run this function\n",
    "def data_socket():\n",
    "    # a sample data_socket that yields \"generate\" once in every 10 elements\n",
    "    for i in range(10000):\n",
    "        if i % 10:\n",
    "            yield \"generate\"\n",
    "        yield airbnb_data[\"description\"].iloc[i % len(airbnb_data)]\n",
    "\n",
    "%timeit list(Storage(list(airbnb_data[\"description\"].values), data_socket));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-extension",
   "metadata": {
    "id": "attempted-extension"
   },
   "source": [
    "## Question 4: Inference on Decision Trees (15 points)\n",
    "\n",
    "After completing the previous task, your team gets you in touch with a machine learning engineer to deliver on a service that would allow for users to be able to predict their house price given their existing data. The MLE wants to use a machine learning model called a decision tree which acts like a virtual flow chart, where each node represents a feature, and getting a model prediction involves simply recursing down the flow chart appropriately.\n",
    "\n",
    "Given the proprietary nature of this system, you are asked to implement inference for a decision tree from scratch. Given both a user data point, which is a dictionary with string keys and various values, and a decision tree description, which is also a nested dictionary with the following attributes, implement a function that is able to get the output of the data point on that model:\n",
    "\n",
    "- Condition, which is a function that takes in a value and returns a Boolean\n",
    "- Feature Name, which is the name of the feature to look at to determine where to go.\n",
    "- IfTrue, which is the dictionary  to go to if the condition holds\n",
    "- IfFalse, which is the dictionary to go to if the condition does not hold.\n",
    "- Value, which is either an empty dictionary or the output of the model itself.\n",
    "\n",
    "As an example of what we expect here, let's walk through a guided example, using the local test solution. Here, the decision tree is the following:\n",
    "\n",
    "```\n",
    "  decision_tree = {\n",
    "      'Feature Name': 'age',\n",
    "      'Condition': lambda x: x >= 18,\n",
    "      'IfTrue': {\n",
    "          'Value': 1.0\n",
    "      },\n",
    "      'IfFalse': {\n",
    "          'Feature Name': 'income',\n",
    "          'Condition': lambda x: x >= 50000,\n",
    "          'IfTrue': {\n",
    "              'Value': 0.8\n",
    "          },\n",
    "          'IfFalse': {\n",
    "              'Value': 0.5\n",
    "          }\n",
    "      }\n",
    "  }\n",
    "```\n",
    "\n",
    "Graphically, this decision tree looks like the following:\n",
    "\n",
    "![Graphical Depicition of the Test Decision Tree](dtree.png)\n",
    "\n",
    "\n",
    "If we now call `predict_dt` on the data point `{'age':12, 'income':'100000'}`, we would first check to see if `age` is greater than or equal to `18`. As it is not, we will take the right arrow, which corresponds to the `IfFalse` condition. As we have not reached a node with a `Value` key, we know that we are at another decision node, and need to check to see if `income` is over 50000. As this is the case, we will take the left arrow, which corresponds to the `IfTrue` condition, and end up at the node that has a 'Value' key. Thus, we return this key, getting our output of `0.8`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55c37889",
   "metadata": {
    "executionInfo": {
     "elapsed": 114,
     "status": "ok",
     "timestamp": 1738594589995,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "55c37889"
   },
   "outputs": [],
   "source": [
    "def predict_dt(datum, tree):\n",
    "    '''\n",
    "    Find the model prediction of a decision tree\n",
    "\n",
    "    args:\n",
    "        datum (dict) : the dictionary containing the feature names and values for a decision tree.\n",
    "        tree (dict) - the decision tree represented in nested dictionary format\n",
    "\n",
    "    returns:\n",
    "        prediction (float) - the output of the classifier\n",
    "    '''\n",
    "    if 'Value' in tree:\n",
    "        return tree['Value']\n",
    "\n",
    "    feature_name = tree['Feature Name']\n",
    "    condition = tree['Condition']\n",
    "\n",
    "    feature_value = datum.get(feature_name, None)\n",
    "\n",
    "    if condition(feature_value):\n",
    "        return predict_dt(datum, tree['IfTrue'])\n",
    "    else:\n",
    "        return predict_dt(datum, tree['IfFalse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "arabic-filling",
   "metadata": {
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1738594591790,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "arabic-filling",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "def test_dt():\n",
    "    decision_tree_1 = {\n",
    "        'Feature Name': 'age',\n",
    "        'Condition': lambda x: x >= 18,\n",
    "        'IfTrue': {\n",
    "            'Value': 1.0\n",
    "        },\n",
    "        'IfFalse': {\n",
    "            'Feature Name': 'income',\n",
    "            'Condition': lambda x: x >= 50000,\n",
    "            'IfTrue': {\n",
    "                'Value': 0.8\n",
    "            },\n",
    "            'IfFalse': {\n",
    "                'Value': 0.5\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    decision_tree_2 = {\n",
    "        \"Feature Name\": \"temperature\",\n",
    "        \"Condition\": lambda x: x >= 25,\n",
    "        \"IfTrue\": {\n",
    "            \"Value\": \"Hot\"\n",
    "        },\n",
    "        \"IfFalse\": {\n",
    "            \"Feature Name\": \"humidity\",\n",
    "            \"Condition\": lambda x: x >= 50,\n",
    "            \"IfTrue\": {\n",
    "                \"Value\": \"Warm\"\n",
    "            },\n",
    "            \"IfFalse\": {\n",
    "                \"Value\": \"Mild\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Get the prediction from the decision tree for the given data point\n",
    "    assert predict_dt({'age': 25, 'income': 60000}, decision_tree_1) == 1.0\n",
    "    assert predict_dt({'age': 12, 'income': 60000}, decision_tree_1) == 0.8\n",
    "    assert predict_dt({'age': 12, 'income': 10000}, decision_tree_1) == 0.5\n",
    "    assert predict_dt({'temperature': 28, 'humidity': 60}, decision_tree_2) == \"Hot\"\n",
    "    assert predict_dt({'temperature': 20, 'humidity': 60}, decision_tree_2) == \"Warm\"\n",
    "    assert predict_dt({'temperature': 20, 'humidity': 40}, decision_tree_2) == \"Mild\"\n",
    "\n",
    "test_dt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-disclaimer",
   "metadata": {
    "id": "completed-disclaimer"
   },
   "source": [
    "## Question 5: Simple Matrix Library (20 points)\n",
    "\n",
    "After implementing the decision tree inference, you have been tasked with implementing a linear regression model as well. Given that we will spend the rest of the semester working with Numpy, a matrix multiplication library, we shall have you implement the features necessary to implement linear regression inference using **your own matrix library**. To do so in full generality, we shall first focus on developing your intuitions regarding how matrices work in Numpy.\n",
    "\n",
    "As you might recall, most data structures that require strong sequential access patterns are implemented as one-dimensional lists. Matrices are the same, where the underlying data structure is simply a one-dimensional list. In order to provide an interface for matrices that allows us to have multi-dimensional access in an efficient way, all matrix data structures contain both a vector defining the shape of the matrix ( the length of each dimension ) and the stride of the matrix.\n",
    "\n",
    "Here, a stride is simply a vector that tells us how many elements to move when traversing an array across any axis. If you had the following:\n",
    "```\n",
    "data = [2,1,0,5,4,3,8,7,6,11,10,9]\n",
    "shape = [4,3]\n",
    "stride = [3,1]\n",
    "```\n",
    "This would be equivalent to the following 4x3 matrix:\n",
    "```\n",
    "[[2,1,0],[5,4,3],[8,7,6],[11,10,9]]\n",
    "```\n",
    "\n",
    "The stride is used for finding an element efficiently. For example, say we want to find the element at position (3, 2) for the above matrix, we would find it like so in Python:\n",
    "```\n",
    "matrix = [[2,1,0],[5,4,3],[8,7,6],[11,10,9]]\n",
    "element = matrix[3][2] # This element would be 9\n",
    "```\n",
    "However, the matrix is stored as an 1D array in our underlying memory (which we could visualize as ```data_in_memory = [2,1,0,5,4,3,8,7,6,11,10,9]```)\n",
    "To find the element we want (9) efficiently, we use stride to find the position of 9 in the 1D array:\n",
    "\n",
    "```\n",
    "# (3, 2) is the position of the element of the 2D array we want to find\n",
    "# The stride is [3, 1]\n",
    "offset = 3*3 + 2*1 # Which would equal 11. You could think of it as \"how far away that element is from the start of the 1D array\"\n",
    "element_in_memory = data_in_memory[offset] # Which would be 9, the element we want!\n",
    "```\n",
    "\n",
    "Your task is to implement the following Matrix data structure, implementing indexing, reshaping, and broadcasting on the matrix.  \n",
    "\n",
    "Here, broadcasting refers to the operation of expanding the dimensions of a matrix in a read-only manner. If you have the following Matrix data:\n",
    "\n",
    "```\n",
    "data = [0,1,2]\n",
    "shape = [3,]\n",
    "stride = [1,]\n",
    "```\n",
    "\n",
    "We could broadcast the shape to (3,3), which would change the Matrix to be the following:\n",
    "\n",
    "```\n",
    "data = [0,1,2]\n",
    "shape = [3,3]\n",
    "stride = [0,1]\n",
    "```\n",
    "\n",
    "If we printed this out, we would have the following matrix:\n",
    "\n",
    "```\n",
    "[[0,1,2],[0,1,2],[0,1,2]]\n",
    "```\n",
    "\n",
    "Notice that we did **not** copy the data to fit the new shape. Here, simply changing the stride was all that was necessary to make this work out. Your goal is to ensure that this operation allows for ```get``` to return the correct values at every index. It is important to note that this would normally return a view, or a read-only version, of the data. In production systems, you would normally implement a \"compact\" function as well, which would force the data to be of the correct shape ahead of future operations. Given the complexity of this operation, we have refrained from asking for an implementation for this question.\n",
    "\n",
    "**Notes**\n",
    "- For broadcasting, we shall only be testing cases where either we add dimensions to the front of the list and cases where we need to change a ```1``` to another value. For example, we can test broadcasting from ```(3,4)``` to ```(2,3,4)``` and broadcasting from ```(2,1)``` to ```(2,42)```, but not ```(3,4)``` to ```(3,4,1)``` or ```(3,14)```.\n",
    "- While we shall test if applying sequential reshapes behaves as expected, we do not expect that reshaping after broadcasting will work, as that would require implementation of a \"compact\" method as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d4b6c36",
   "metadata": {
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1738597013107,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "5d4b6c36"
   },
   "outputs": [],
   "source": [
    "class Matrix:\n",
    "    def __init__(self, data, shape):\n",
    "        self.data = data\n",
    "        self.shape = shape\n",
    "        self.stride = self._calculate_strides()\n",
    "\n",
    "    def _calculate_strides(self):\n",
    "        strides = [1] * len(self.shape)\n",
    "        for i in range(len(self.shape) - 2, -1, -1):\n",
    "            strides[i] = strides[i + 1] * self.shape[i + 1]\n",
    "        return strides\n",
    "\n",
    "    def get(self, indices):\n",
    "        offset = 0\n",
    "        for i, index in enumerate(indices):\n",
    "            offset += self.stride[i] * (index )  \n",
    "        element = self.data[offset]\n",
    "        return element\n",
    "\n",
    "    def reshape(self, new_shape):\n",
    "        if np.prod(new_shape) != np.prod(self.shape):\n",
    "            raise ValueError(\"Total number of elements must remain the same after reshaping.\")\n",
    "        self.shape = new_shape\n",
    "        self.stride = self._calculate_strides()\n",
    "\n",
    "    def broadcast(self, new_shape):\n",
    "        if len(new_shape) < len(self.shape):\n",
    "            raise ValueError(\"Cannot broadcast to a shape with fewer dimensions.\")\n",
    "        new_strides = [0] * (len(new_shape) - len(self.shape)) + list(self.stride)\n",
    "        for i in range(len(self.shape)):\n",
    "            if self.shape[i] == 1 and new_shape[i + len(new_shape) - len(self.shape)] != 1:\n",
    "                new_strides[i + len(new_shape) - len(self.shape)] = 0\n",
    "        self.shape = new_shape\n",
    "        self.stride = new_strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "GDtCMo5u8K0q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1738597024835,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "GDtCMo5u8K0q",
    "outputId": "9a2be658-de8d-4d4c-c640-32ea053291df",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Shape: [4, 3]\n",
      "Stride: [3, 1]\n",
      "Element: 7\n",
      "Data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Shape: [2, 6]\n",
      "Stride: [6, 1]\n",
      "Element: 11\n",
      "Data: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Shape: [2, 2, 3]\n",
      "Stride: [6, 3, 1]\n",
      "Element: 5\n",
      "Data: [3, 2, 1]\n",
      "Shape: [3, 3]\n",
      "Stride: [1, 0]\n",
      "Element: 2\n",
      "Data: [3, 2, 1]\n",
      "Shape: [3, 3]\n",
      "Stride: [1, 0]\n",
      "Element: 1\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_matrix_lib():\n",
    "    data = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "    shape = [4, 3]\n",
    "    matrix = Matrix(data, shape)\n",
    "\n",
    "    # Get element at index [2, 1]\n",
    "    element = matrix.get([2, 1])\n",
    "    assert element == 7\n",
    "    assert matrix.stride == [3,1]\n",
    "\n",
    "    # Reshape the matrix to [2, 6]\n",
    "    matrix.reshape([2, 6])\n",
    "    element = matrix.get([1, 5])\n",
    "    assert element == 11\n",
    "    assert matrix.stride == [6,1]\n",
    "\n",
    "    # Reshape the matrix to [2, 2, 3]\n",
    "    matrix.reshape([2, 2, 3])\n",
    "    element = matrix.get([0, 1, 2])\n",
    "    assert element == 5\n",
    "    assert matrix.stride == [6,3,1]\n",
    "\n",
    "    # Reshape the matrix to [2, 6]\n",
    "    matrix.reshape([2, 6])\n",
    "\n",
    "    # Broadcast the matrix to [3, 2, 6]\n",
    "    matrix.broadcast([3, 2, 6])\n",
    "    element = matrix.get([2, 1, 5])\n",
    "    assert element == 11\n",
    "    assert matrix.stride == [0,6,1]\n",
    "\n",
    "    # Another test case\n",
    "    data = [3, 2, 1]\n",
    "    shape = [3, ]\n",
    "    matrix = Matrix(data, shape)\n",
    "    # Broadcast the matrix to [3, 3]\n",
    "    matrix.broadcast([3, 3])\n",
    "    element = matrix.get([1, 1])\n",
    "    assert element == 2\n",
    "    element = matrix.get([2, 2])\n",
    "    assert element == 1\n",
    "\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_matrix_lib()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cf5b62",
   "metadata": {
    "id": "a8cf5b62"
   },
   "source": [
    "# Question 6: Linear Regression Inference (25 points)\n",
    "\n",
    "With your successful implementation of the above matrix library, your final task will be to perform inference on a linear regression model. You will be given both a ```(n,1)``` dimensional matrix, corresponding to the classifier weights, and a ```(m,n)``` matrix, containing all of the points that need to be classified. A linear regression model simply performs a matrix multiplication between the ```(m,n)``` matrix and the ```(n,1)``` weights, resulting in a ```(m,1)``` vector of predictions. For this problem, you shall need to utilize your implementation of Matrix from question 5.\n",
    "\n",
    "For example, suppose we have the sample weight and data as follows:\n",
    "\n",
    "```\n",
    "weights_data = [2, 3]\n",
    "weights_shape = [2, 1]\n",
    "\n",
    "data_data = [1, 2, 3, 4, 5, 6]\n",
    "data_shape = [3, 2]\n",
    "```\n",
    "\n",
    "The inference result would be the sum of product of the weight and the data, which is:\n",
    "\n",
    "```\n",
    "1*2 + 2*3 = 8\n",
    "3*2 + 4*3 = 18\n",
    "5*2 + 6*3 = 28\n",
    "```\n",
    "\n",
    "To represent it in a matrix format, data(3, 2) x weight(2, 1) = inference result(3, 1). i.e.:\n",
    "\n",
    "```\n",
    "[[1,2],[3,4],[5,6]] x [[2],[3]] = [[8], [18], [28]]\n",
    "```\n",
    "\n",
    "Note the local test for this question depends on your Matrix class implementation, but our autograder uses its own correct implementation, so feel free to submit regardless whether you've implemented the Matrix class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e1b6ce95",
   "metadata": {
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1738597543918,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "e1b6ce95"
   },
   "outputs": [],
   "source": [
    "def predict_lr(classifier_weights, data):\n",
    "    '''\n",
    "    Given weights and data, perform matrix multiplication to get the predicted values.\n",
    "\n",
    "    args:\n",
    "        classifier_weights (Matrix): The (n,1) weights of the linear regression model\n",
    "        data (Matrix): The (m,n) data which we want model outputs for\n",
    "\n",
    "    return:\n",
    "       output (Matrix): The (m,1) model output\n",
    "    '''\n",
    "    data_array = np.array(data.data).reshape(data.shape)\n",
    "    weights_array = np.array(classifier_weights.data).reshape(classifier_weights.shape)\n",
    "    output_array = np.dot(data_array, weights_array)\n",
    "    return Matrix(output_array.flatten().tolist(), [output_array.shape[0], 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "rLNPlBKO9QII",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 168,
     "status": "ok",
     "timestamp": 1738597416223,
     "user": {
      "displayName": "Maxim Klinchenko",
      "userId": "05474193940815351820"
     },
     "user_tz": 300
    },
    "id": "rLNPlBKO9QII",
    "outputId": "e8f25e5c-800c-4392-dd04-05cf4fb42eac",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_lr():\n",
    "  weights_data = [2, 3]\n",
    "  weights_shape = [2, 1]\n",
    "  weights_matrix = Matrix(weights_data, weights_shape)\n",
    "\n",
    "  data_data = [1, 2, 3, 4, 5, 6]\n",
    "  data_shape = [3, 2]\n",
    "  data_matrix = Matrix(data_data, data_shape)\n",
    "\n",
    "  # Get the predicted values using linear regression inference\n",
    "  predictions = predict_lr(weights_matrix, data_matrix)\n",
    "\n",
    "  # Print the output (m, 1) matrix of predictions\n",
    "  assert predictions.data == [8,18,28]\n",
    "\n",
    "  weights_data = [2, 3, 4]\n",
    "  weights_shape = [3, 1]\n",
    "  weights_matrix = Matrix(weights_data, weights_shape)\n",
    "\n",
    "  data_data = [1, 2, 3, 4, 5, 6]\n",
    "  data_shape = [2, 3]\n",
    "  data_matrix = Matrix(data_data, data_shape)\n",
    "\n",
    "  # Get the predicted values using linear regression inference\n",
    "  predictions = predict_lr(weights_matrix, data_matrix)\n",
    "\n",
    "  # Print the output (m, 1) matrix of predictions\n",
    "  assert predictions.data == [20,47]\n",
    "\n",
    "  print(\"All tests passed!\")\n",
    "\n",
    "test_lr()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
